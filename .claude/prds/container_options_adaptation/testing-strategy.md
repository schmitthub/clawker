# Testing Strategy

> Generated by testing-analyzer for docker/docker-cli

## Testing Summary

**Test Framework**: Go standard testing library (`testing` package)
**Test Location**: Alongside source code (e.g., `opts_test.go` next to `opts.go`)
**Test Types**: Unit tests (primary), integration tests (via fake client pattern)
**Coverage Tool**: Go built-in coverage with `-coverprofile`
**CI Integration**: Yes (via Docker buildx bake and GitHub Actions)

---

## Test Infrastructure

### Framework Configuration

The Docker CLI uses Go's standard testing framework with minimal external dependencies. Tests are executed using `gotestsum` for better output formatting.

**Key Testing Dependencies** (from imports):
```go
import (
    "testing"
    "github.com/spf13/pflag"           // Flag parsing
    "gotest.tools/v3/assert"           // Assertion library
    is "gotest.tools/v3/assert/cmp"    // Comparison helpers (aliased)
    "gotest.tools/v3/skip"             // Conditional test skipping
    "gotest.tools/v3/fs"               // Filesystem test helpers
    "gotest.tools/v3/golden"           // Golden file testing
    "github.com/google/go-cmp/cmp/cmpopts" // Deep comparison options
)
```

**Test Execution** (from Dockerfile, line 100):
```bash
gotestsum -- -coverprofile=/tmp/coverage.txt \
    $(go list ./... | grep -vE '/vendor/|/e2e/|/cmd/docker-trust')
```

**Local Test Execution** (from Makefile, line 37):
```bash
gotestsum -- ${TESTDIRS:-$(shell go list ./... | grep -vE '/vendor/|/e2e/|/cmd/docker-trust')} $(TESTFLAGS)
```

### Directory Structure

```
cli/command/container/
├── opts.go                    # Source: container options parsing
├── opts_test.go              # Tests: 26 test functions, 1156 lines
├── client_test.go            # Fake client implementation (235 lines)
├── create_test.go            # Container creation tests
├── run_test.go               # Container run tests
├── attach_test.go            # Attach functionality tests
├── [other]_test.go          # Per-feature test files
└── testdata/
    ├── valid.env             # Test fixture: environment file
    ├── valid.label           # Test fixture: label file
    ├── utf8.env              # Test fixture: UTF-8 with BOM
    ├── utf16.env             # Test fixture: UTF-16 (error case)
    └── utf16be.env           # Test fixture: UTF-16BE (error case)

internal/test/
├── cli.go                    # FakeCli implementation
├── cmd.go                    # Command test helpers
├── doc.go                    # Package documentation
├── randomid.go               # Random ID generation
├── strings.go                # String test helpers
└── writer.go                 # Writer test helpers
```

---

## Test Types

### Unit Tests

- **Location**: `cli/command/container/opts_test.go` (primary focus)
- **Count**: 26 test functions covering option parsing
- **Scope**: Flag parsing, validation, configuration transformation
- **Isolation**: Uses `setupRunFlags()` and `parseRun()` helpers for isolated testing

**Example Unit Test**:
```go
func TestValidateAttach(t *testing.T) {
    valid := []string{
        "stdin",
        "stdout",
        "stderr",
        "STDIN",
        "STDOUT",
        "STDERR",
    }
    if _, err := validateAttach("invalid"); err == nil {
        t.Fatal("Expected error with [valid streams are STDIN, STDOUT and STDERR], got nothing")
    }

    for _, attach := range valid {
        value, err := validateAttach(attach)
        if err != nil {
            t.Fatal(err)
        }
        if value != strings.ToLower(attach) {
            t.Fatalf("Expected [%v], got [%v]", attach, value)
        }
    }
}
```

### Integration Tests (Fake Client Pattern)

- **Location**: `cli/command/container/create_test.go`, `run_test.go`, etc.
- **Scope**: Testing commands with mocked Docker API client
- **Approach**: Function injection via `fakeClient` struct

**Fake Client Implementation** (`client_test.go`):
```go
type fakeClient struct {
    client.Client
    inspectFunc             func(string) (client.ContainerInspectResult, error)
    execInspectFunc         func(execID string) (client.ExecInspectResult, error)
    execCreateFunc          func(containerID string, options client.ExecCreateOptions) (client.ExecCreateResult, error)
    createContainerFunc     func(options client.ContainerCreateOptions) (client.ContainerCreateResult, error)
    containerStartFunc      func(containerID string, options client.ContainerStartOptions) (client.ContainerStartResult, error)
    imagePullFunc           func(ctx context.Context, parentReference string, options client.ImagePullOptions) (client.ImagePullResponse, error)
    // ... additional function fields for other operations
}

// Methods delegate to function fields if set, otherwise return empty results
func (f *fakeClient) ContainerCreate(_ context.Context, options client.ContainerCreateOptions) (client.ContainerCreateResult, error) {
    if f.createContainerFunc != nil {
        return f.createContainerFunc(options)
    }
    return client.ContainerCreateResult{}, nil
}
```

**Example Integration Test**:
```go
func TestCreateContainerImagePullPolicy(t *testing.T) {
    apiClient := &fakeClient{
        createContainerFunc: func(options client.ContainerCreateOptions) (client.ContainerCreateResult, error) {
            return client.ContainerCreateResult{ID: "abcdef"}, nil
        },
        imagePullFunc: func(ctx context.Context, parentReference string, options client.ImagePullOptions) (client.ImagePullResponse, error) {
            pullCounter++
            return fakeStreamResult{ReadCloser: io.NopCloser(strings.NewReader(""))}, nil
        },
    }
    fakeCLI := test.NewFakeCli(apiClient)
    id, err := createContainer(context.Background(), fakeCLI, config, &createOptions{
        pull: PullImageMissing,
    })

    assert.Check(t, err)
    assert.Check(t, is.Equal("abcdef", id))
}
```

### Test Data Files

Tests use fixture files in `testdata/` for:
- Environment variable files (`.env`)
- Label files (`.label`)
- Encoding edge cases (UTF-8 BOM, UTF-16)

**Usage Pattern**:
```go
config, _, _, err := parseRun([]string{"--env-file=testdata/valid.env", "img", "cmd"})
assert.NilError(t, err)
assert.Check(t, is.Len(config.Env, 1))
assert.Check(t, is.Equal(config.Env[0], "ENV1=value1"))
```

---

## Test Patterns

### Structure Pattern: Table-Driven Tests

The codebase extensively uses table-driven tests for comprehensive coverage of input variations.

**Pattern Example** (`TestParseRunLinks`):
```go
func TestParseRunLinks(t *testing.T) {
    tests := []struct {
        name               string
        input              string
        expHostConfigLinks []string
        expNetConfigLinks  map[string][]string
    }{
        {
            name:               "default/onelink",
            input:              "--link a:b",
            expHostConfigLinks: []string{"a:b"},
            expNetConfigLinks:  map[string][]string{"default": nil},
        },
        {
            name:               "default/twolinks",
            input:              "--link a:b --link c:d",
            expHostConfigLinks: []string{"a:b", "c:d"},
            expNetConfigLinks:  map[string][]string{"default": nil},
        },
        // ... more test cases
    }

    for _, tc := range tests {
        t.Run(tc.name, func(t *testing.T) {
            _, hostConfig, netConfig := mustParse(t, tc.input)
            assert.Check(t, is.DeepEqual(hostConfig.Links, tc.expHostConfigLinks))
            assert.Check(t, is.Len(netConfig.EndpointsConfig, len(tc.expNetConfigLinks)))
            for netName, expLinks := range tc.expNetConfigLinks {
                nc, ok := netConfig.EndpointsConfig[netName]
                assert.Assert(t, ok)
                assert.Check(t, is.DeepEqual(nc.Links, expLinks))
            }
        })
    }
}
```

**Key Characteristics**:
1. Anonymous struct slice defines test cases
2. Each case has descriptive `name` field (used in `t.Run`)
3. Input and expected output fields clearly separated
4. `t.Run` creates subtests for better isolation and reporting
5. Test names use descriptive patterns (e.g., "default/onelink", "bridge/onelink")

**Another Pattern Example** (`TestParseNetworkConfig`):
```go
tests := []struct {
    name            string
    flags           []string
    expected        map[string]*networktypes.EndpointSettings
    expectedHostCfg container.HostConfig
    expectedErr     string
}{
    {
        name:            "single-network-legacy",
        flags:           []string{"--network", "net1"},
        expected:        map[string]*networktypes.EndpointSettings{},
        expectedHostCfg: container.HostConfig{NetworkMode: "net1"},
    },
    {
        name:        "conflict-network",
        flags:       []string{"--network", "duplicate", "--network", "name=duplicate"},
        expectedErr: `network "duplicate" is specified multiple times`,
    },
    // ... 15+ test cases total
}
```

### Helper Functions

Three critical test helper functions enable DRY testing:

#### 1. `setupRunFlags()` - Flag Setup Helper

```go
func setupRunFlags() (*pflag.FlagSet, *containerOptions) {
    flags := pflag.NewFlagSet("run", pflag.ContinueOnError)
    flags.SetOutput(io.Discard)  // Suppress flag parsing errors in tests
    flags.Usage = nil
    copts := addFlags(flags)      // Adds all container flags
    return flags, copts
}
```

**Purpose**: Creates a fresh flag set with all container options for isolated testing.

#### 2. `parseRun()` - Parsing Helper

```go
func parseRun(args []string) (*container.Config, *container.HostConfig, *networktypes.NetworkingConfig, error) {
    flags, copts := setupRunFlags()
    if err := flags.Parse(args); err != nil {
        return nil, nil, nil, err
    }
    containerCfg, err := parse(flags, copts, runtime.GOOS)
    if err != nil {
        return nil, nil, nil, err
    }
    return containerCfg.Config, containerCfg.HostConfig, containerCfg.NetworkingConfig, err
}
```

**Purpose**: Parses flag strings into container config objects, returning the three key configuration structures.

#### 3. `mustParse()` - Success-Expected Parsing Helper

```go
func mustParse(t *testing.T, args string) (*container.Config, *container.HostConfig, *networktypes.NetworkingConfig) {
    t.Helper()  // Marks this as a test helper for better error reporting
    config, hostConfig, nwConfig, err := parseRun(append(strings.Split(args, " "), "ubuntu", "bash"))
    assert.NilError(t, err)
    return config, hostConfig, nwConfig
}
```

**Purpose**: Parses args and automatically fails test if parsing errors occur. Adds default image and command.

**Key Design Decisions**:
- `t.Helper()` ensures error lines point to test code, not helper code
- Auto-appends `"ubuntu", "bash"` so tests don't need to repeat image/command
- Splits space-delimited string into argv for ergonomic test writing

**Usage Comparison**:

```go
// Error case - use parseRun directly
_, _, _, err := parseRun([]string{"--invalid-flag", "img", "cmd"})
assert.ErrorContains(t, err, "expected error message")

// Success case - use mustParse
config, hostConfig, _ := mustParse(t, "--memory=1G")
assert.Check(t, is.Equal(int64(1073741824), hostConfig.Memory))
```

#### 4. Additional Helper: `setupPlatformVolume()`

```go
func setupPlatformVolume(u []string, w []string) ([]string, string) {
    var a []string
    if runtime.GOOS == "windows" {
        a = w
    } else {
        a = u
    }
    s := ""
    for _, v := range a {
        s = s + "-v " + v + " "
    }
    return a, s
}
```

**Purpose**: Handles platform-specific volume path differences (Unix vs Windows) in tests.

#### 5. Additional Helper: `mustParseMAC()`

```go
func mustParseMAC(s string) networktypes.HardwareAddr {
    mac, err := net.ParseMAC(s)
    if err != nil {
        panic(err)
    }
    return networktypes.HardwareAddr(mac)
}
```

**Purpose**: Converts MAC address strings to hardware address objects, panicking on invalid input (acceptable in test fixtures).

---

## Fake Client Pattern for Integration Testing

### FakeCli Test Utility (`internal/test/cli.go`)

The test package provides a comprehensive fake CLI implementation:

```go
type FakeCli struct {
    command.DockerCli
    client         client.APIClient
    configfile     *configfile.ConfigFile
    out            *streams.Out
    outBuffer      *bytes.Buffer  // Captures stdout
    err            *streams.Out
    errBuffer      *bytes.Buffer  // Captures stderr
    in             *streams.In
    // ... additional fields
}

func NewFakeCli(apiClient client.APIClient, opts ...func(*FakeCli)) *FakeCli {
    outBuffer := new(bytes.Buffer)
    errBuffer := new(bytes.Buffer)
    return &FakeCli{
        client:    apiClient,
        out:       streams.NewOut(outBuffer),
        outBuffer: outBuffer,
        err:       streams.NewOut(errBuffer),
        errBuffer: errBuffer,
        in:        streams.NewIn(io.NopCloser(strings.NewReader(""))),
        configfile: configfile.New(""),  // Empty filename prevents file creation
    }
}

// Accessors for test assertions
func (c *FakeCli) OutBuffer() *bytes.Buffer { return c.outBuffer }
func (c *FakeCli) ErrBuffer() *bytes.Buffer { return c.errBuffer }
```

**Key Features**:
1. Captures stdout/stderr in buffers for assertion
2. Accepts functional options for customization
3. Empty config filename prevents test pollution
4. Implements full `command.Cli` interface

**Usage Pattern**:
```go
fakeCLI := test.NewFakeCli(&fakeClient{
    createContainerFunc: func(options client.ContainerCreateOptions) (client.ContainerCreateResult, error) {
        return client.ContainerCreateResult{Warnings: []string{"warning"}}, nil
    },
})
cmd := newCreateCommand(fakeCLI)
cmd.SetArgs([]string{"image:tag"})
err := cmd.Execute()

assert.NilError(t, err)
assert.Check(t, is.Contains(fakeCLI.ErrBuffer().String(), "warning"))
```

### Per-Package Fake Client (`client_test.go`)

Each command package defines a `fakeClient` with function injection:

**Structure**:
```go
type fakeClient struct {
    client.Client  // Embeds base client
    inspectFunc          func(string) (client.ContainerInspectResult, error)
    createContainerFunc  func(options client.ContainerCreateOptions) (client.ContainerCreateResult, error)
    // ... function fields for each API method
    Version string
}
```

**Implementation Pattern**:
```go
func (f *fakeClient) ContainerCreate(_ context.Context, options client.ContainerCreateOptions) (client.ContainerCreateResult, error) {
    if f.createContainerFunc != nil {
        return f.createContainerFunc(options)
    }
    return client.ContainerCreateResult{}, nil  // Safe default
}
```

**Benefits**:
1. **Selective mocking**: Only override methods relevant to the test
2. **Safe defaults**: Unset methods return zero values, tests don't crash
3. **Closure capture**: Can capture variables in test scope
4. **Stateful testing**: Can count calls, check sequences

**Advanced Example**:
```go
pullCounter := 0
apiClient := &fakeClient{
    createContainerFunc: func(options client.ContainerCreateOptions) (client.ContainerCreateResult, error) {
        // First call fails (image not found), second succeeds
        if pullCounter == 0 {
            return client.ContainerCreateResult{}, fakeNotFound{}
        }
        return client.ContainerCreateResult{ID: containerID}, nil
    },
    imagePullFunc: func(ctx context.Context, ref string, opts client.ImagePullOptions) (client.ImagePullResponse, error) {
        pullCounter++
        return fakeStreamResult{ReadCloser: io.NopCloser(strings.NewReader(""))}, nil
    },
}
// Test can verify pullCounter incremented correctly
```

---

## Edge Case Coverage

### Platform-Specific Testing

Tests use `runtime.GOOS` to handle platform differences:

```go
func TestParseWithVolumes(t *testing.T) {
    // Platform-specific paths
    arr, tryit := setupPlatformVolume(
        []string{`/tmp`},           // Unix
        []string{`c:\tmp`},         // Windows
    )
    config, hostConfig, _ := mustParse(t, tryit)
    // ... assertions
}

func TestValidateDevice(t *testing.T) {
    skip.If(t, runtime.GOOS != "linux") // Skip on Windows/macOS
    // ... Linux-specific device validation tests
}
```

### Error Cases

Tests explicitly validate error messages using table-driven approach:

```go
func TestParseRunWithInvalidArgs(t *testing.T) {
    tests := []struct {
        args  []string
        error string
    }{
        {
            args:  []string{"-a", "ubuntu", "bash"},
            error: `invalid argument "ubuntu" for "-a, --attach" flag: valid streams are STDIN, STDOUT and STDERR`,
        },
        {
            args:  []string{"-z", "--rm", "ubuntu", "bash"},
            error: `unknown shorthand flag: 'z' in -z`,
        },
    }
    flags, _ := setupRunFlags()
    for _, tc := range tests {
        t.Run(strings.Join(tc.args, " "), func(t *testing.T) {
            assert.Error(t, flags.Parse(tc.args), tc.error)
        })
    }
}
```

### Encoding Edge Cases

Tests validate handling of various file encodings:

```go
func TestParseEnvfileVariablesWithBOMUnicode(t *testing.T) {
    // UTF-8 with BOM - should work
    config, _, _, err := parseRun([]string{"--env-file=testdata/utf8.env", "img", "cmd"})
    assert.NilError(t, err)

    // UTF-16 with BOM - should error
    e := "invalid utf8 bytes at line"
    _, _, _, err = parseRun([]string{"--env-file=testdata/utf16.env", "img", "cmd"})
    assert.Check(t, is.ErrorContains(err, e))
}
```

### Conflict Detection

Tests verify mutually exclusive option detection:

```go
{
    name:        "conflict-options-alias",
    flags:       []string{"--network", "name=net1,alias=web1", "--network-alias", "web1"},
    expectedErr: `conflicting options: cannot specify both --network-alias and per-network alias`,
},
{
    name:        "conflict-options-mac-address",
    flags:       []string{"--network", "name=net1,mac-address=02:32:1c:23:00:04", "--mac-address", "02:32:1c:23:00:04"},
    expectedErr: `conflicting options: cannot specify both --mac-address and per-network MAC address`,
},
```

### Validation Edge Cases

Tests cover boundary conditions and invalid input:

```go
func TestParseWithExpose(t *testing.T) {
    t.Run("invalid", func(t *testing.T) {
        tests := map[string]string{
            ":":                   `invalid range format for --expose: invalid start port ':': invalid syntax`,
            "8080:9090":           `invalid range format for --expose: invalid start port '8080:9090': invalid syntax`,
            "/tcp":                `invalid range format for --expose: invalid start port '': value is empty`,
            "NaN/tcp":             `invalid range format for --expose: invalid start port 'NaN': invalid syntax`,
            "1234567890-8080/tcp": `invalid range format for --expose: invalid start port '1234567890': value out of range`,
        }
        for expose, expectedError := range tests {
            t.Run(expose, func(t *testing.T) {
                _, _, _, err := parseRun([]string{fmt.Sprintf("--expose=%v", expose), "img", "cmd"})
                assert.Error(t, err, expectedError)
            })
        }
    })
}
```

---

## Test Naming Conventions

### Test Function Names

Pattern: `Test<FunctionUnderTest><Aspect>`

Examples:
- `TestValidateAttach` - Tests `validateAttach` function
- `TestParseRunLinks` - Tests link parsing in run command
- `TestParseWithVolumes` - Tests volume flag parsing
- `TestRunFlagsParseWithMemory` - Tests memory flag parsing

### Subtest Names

**Descriptive Pattern**: Used in table-driven tests

```go
t.Run(tc.name, func(t *testing.T) { ... })
```

Examples:
- `"default/onelink"` - Default network with one link
- `"userdefnet/twolinks"` - User-defined network with two links
- `"conflict-options-alias"` - Testing alias option conflict
- `"invalid-mixed-network-types"` - Testing invalid network mixing

**Auto-Generated Pattern**: Uses input as name

```go
t.Run(tc.input, func(t *testing.T) { ... })
t.Run(strings.Join(tc.args, " "), func(t *testing.T) { ... })
```

### File Naming

- `<feature>_test.go` - Tests for `<feature>.go`
- `client_test.go` - Fake client for package tests
- `testdata/` - Test fixture directory

---

## Assertion Patterns

### Primary Assertion Library: `gotest.tools/v3/assert`

**Import Pattern**:
```go
import (
    "gotest.tools/v3/assert"
    is "gotest.tools/v3/assert/cmp"  // Comparison helpers aliased
)
```

### Core Assertions

#### 1. `assert.NilError()` - Assert no error

```go
_, hostConfig, _ := mustParse(t, "--memory=1G")
assert.NilError(t, err)  // Fails test if err != nil
```

#### 2. `assert.Error()` - Assert specific error message

```go
err := flags.Parse(args)
assert.Error(t, err, "expected error message")  // Checks exact match
```

#### 3. `assert.ErrorContains()` - Assert error contains substring

```go
err := flags.Parse(args)
assert.ErrorContains(t, err, `invalid argument "invalid"`)  // Substring match
```

#### 4. `assert.Check()` - Non-fatal assertion

```go
assert.Check(t, is.Equal(hostConfig.Memory, int64(1073741824)))
// Test continues even if check fails
```

#### 5. `assert.Assert()` - Fatal assertion

```go
nc, ok := netConfig.EndpointsConfig[netName]
assert.Assert(t, ok)  // Test stops if assertion fails
// Safe to use nc below
```

#### 6. `assert.DeepEqual()` - Deep equality check

```go
assert.DeepEqual(t, config.Labels, expected)
assert.DeepEqual(t, nwConfig.EndpointsConfig, tc.expected,
    cmpopts.EquateComparable(netip.Addr{}))  // With comparison options
```

#### 7. `assert.Equal()` - Simple equality

```go
assert.Equal(t, config.AttachStdin, tc.expected.AttachStdin)
assert.Check(t, is.Equal(int64(1073741824), hostConfig.Memory))
```

### Comparison Helpers (`is` package)

All used with `assert.Check()` or `assert.Assert()`:

#### `is.Equal()`
```go
assert.Check(t, is.Equal(tc.ExpectedID, id))
assert.Check(t, is.Equal(tc.ExpectedPulls, pullCounter))
```

#### `is.DeepEqual()`
```go
assert.Check(t, is.DeepEqual(hostConfig.Links, tc.expHostConfigLinks))
assert.Check(t, is.DeepEqual(hostConfig.RestartPolicy, tc.expected))
```

#### `is.Len()`
```go
assert.Check(t, is.Len(config.ExposedPorts, 2))
assert.Check(t, is.Len(netConfig.EndpointsConfig, len(tc.expNetConfigLinks)))
```

#### `is.Contains()`
```go
assert.Check(t, is.Contains(fakeCLI.ErrBuffer().String(), "warning"))
```

#### `is.Nil()`
```go
assert.Check(t, is.Nil(err))
assert.Check(t, is.Nil(hostConfig))
```

#### `is.Error()`
```go
assert.Check(t, is.Error(err, tc.expectedErr))  // Exact match
```

#### `is.ErrorContains()`
```go
assert.Check(t, is.ErrorContains(err, tc.ExpectedErrMsg))  // Substring
```

### Assertion Strategy

**Check vs Assert**:
- `assert.Check()` - Non-fatal, test continues, reports all failures
- `assert.Assert()` - Fatal, test stops, use when subsequent code depends on result

**Example showing both**:
```go
nc, ok := netConfig.EndpointsConfig[netName]
assert.Assert(t, ok)  // MUST pass, nc used below
assert.Check(t, is.DeepEqual(nc.Links, expLinks))  // Can fail, test continues
```

### Deep Equality with Options

For types with special comparison needs:

```go
assert.DeepEqual(t, nwConfig.EndpointsConfig, tc.expected,
    cmpopts.EquateComparable(netip.Addr{}))
```

This handles `netip.Addr` comparison correctly.

### Golden File Testing

For complex output validation:

```go
golden.Assert(t, fakeCLI.ErrBuffer().String(), tc.name+".golden")
```

Compares output to a saved golden file in `testdata/`.

---

## Coverage Approach

### Tool

**Coverage Tool**: Go built-in coverage (`go test -coverprofile`)
**Aggregation**: `gotestsum` with coverage profile

### Execution

**Docker Build** (Dockerfile line 100):
```dockerfile
RUN --mount=type=bind,target=.,rw \
    --mount=type=cache,target=/root/.cache \
    --mount=type=cache,target=/go/pkg/mod \
    gotestsum -- -coverprofile=/tmp/coverage.txt \
        $(go list ./... | grep -vE '/vendor/|/e2e/|/cmd/docker-trust')
```

**Local Execution** (Makefile line 42):
```bash
gotestsum -- $(shell go list ./... | grep -vE '/vendor/|/e2e/|/cmd/docker-trust') \
    -coverprofile=$(CURDIR)/build/coverage/coverage.txt
```

### Thresholds

**No explicit coverage thresholds enforced** in the codebase. Coverage is collected but not gated.

### Exclusions

- `/vendor/` - Third-party dependencies
- `/e2e/` - End-to-end tests (run separately)
- `/cmd/docker-trust` - Trust plugin (separate module)

### Coverage Strategy

The project focuses on **unit test coverage** of:
1. Flag parsing and validation
2. Configuration transformation
3. Error handling
4. Platform-specific logic

**Not covered by unit tests** (tested via e2e):
- Actual Docker daemon interaction
- Full command execution flow
- Network/filesystem side effects

---

## CI Configuration

### CI System

**Primary**: GitHub Actions
**Build System**: Docker buildx bake

### Test Execution

**Build Workflow** (`.github/workflows/build.yml`):
```yaml
# Tests run via docker buildx bake
docker buildx bake test
```

**Test Target** (docker-bake.hcl, line 143):
```hcl
target "test" {
    inherits = ["_common"]
    target = "test"
    output = ["type=cacheonly"]
}
```

This builds the `test` stage in the Dockerfile (line 94-100).

### Test Coverage Target

```hcl
target "test-coverage" {
    inherits = ["_common"]
    target = "test-coverage"
    output = ["build/coverage"]
}
```

Extracts coverage report from the test stage.

### Parallelization

**Not explicitly configured** in the test infrastructure. Tests run sequentially within the Docker container.

However, Docker buildx supports parallel builds, and tests could be sharded by package if needed.

### Test Ordering

**Natural Go ordering**: Tests run in package order as discovered by `go list ./...`

Within a package, Go randomizes test order by default.

### Failure Handling

**Fail-fast**: Test execution stops on first package failure.

`gotestsum` provides better error formatting than standard `go test`.

---

## Quality Assessment

### Strengths

1. **Comprehensive table-driven tests**:
   - `TestParseNetworkConfig` has 15+ test cases covering various network configurations
   - `TestParseWithExpose` validates invalid and valid port formats
   - Each test case is clearly named and documented

2. **Excellent test isolation**:
   - Helper functions (`setupRunFlags`, `parseRun`, `mustParse`) ensure fresh state
   - No shared state between tests
   - Each test creates its own flag set

3. **Clear separation of concerns**:
   - `opts_test.go` focuses purely on option parsing
   - `client_test.go` provides fake client infrastructure
   - `create_test.go`, `run_test.go` test command execution

4. **Robust fake client pattern**:
   - Function injection allows precise control
   - Safe defaults prevent test crashes
   - Supports stateful testing (counters, sequences)

5. **Platform-aware testing**:
   - `runtime.GOOS` checks for platform-specific tests
   - `skip.If()` for conditional test execution
   - Separate test data for Windows/Unix

6. **Meaningful test names**:
   - Function names describe what's tested
   - Subtest names describe specific scenarios
   - Easy to identify failing tests

7. **Consistent assertion style**:
   - `gotest.tools/v3/assert` used throughout
   - `is` alias for comparison helpers
   - Clear distinction between fatal/non-fatal assertions

8. **Edge case coverage**:
   - Invalid input validation
   - Encoding edge cases (UTF-8 BOM, UTF-16)
   - Conflict detection between flags
   - Boundary conditions (port ranges, memory limits)

### Concerns

1. **No coverage thresholds**:
   - Coverage is collected but not enforced
   - Could allow coverage to drift downward over time
   - No visibility into which code lacks coverage

2. **Limited integration test coverage**:
   - Fake client pattern tests command logic but not actual Docker API interaction
   - No validation that fake client matches real API behavior
   - Network and I/O operations not tested at integration level

3. **Test data management**:
   - Some test data embedded in code (MAC addresses, IP addresses)
   - Could benefit from test data factories
   - Hard-coded "ubuntu bash" in `mustParse` could be more flexible

4. **Platform testing limitations**:
   - Windows/macOS tests skip device validation
   - No Windows-specific CI validation
   - Platform-specific code may not be regularly tested

5. **Assertion consistency**:
   - Mix of `assert.NilError(t, err)` and `assert.Check(t, err)`
   - Mix of `assert.Equal()` and `is.Equal()`
   - Some tests use `t.Fatal()` directly instead of assertion library

6. **No performance testing**:
   - Flag parsing performance not validated
   - No benchmarks for option parsing
   - Could have performance regressions

7. **Golden file usage unclear**:
   - Golden files mentioned but limited usage
   - No clear guidance on when to use golden files vs direct assertions

### Testing Debt

1. **Incomplete error message testing**:
   - Some error paths test for existence of error but not message content
   - Could lead to unhelpful error messages shipping

2. **Network configuration complexity**:
   - Network tests are complex with many edge cases
   - Could benefit from additional helper functions
   - Some test cases overlap in coverage

3. **Platform-specific coverage gaps**:
   - Device tests skip on Windows/macOS
   - Volume tests have Windows-specific paths but may not run on Windows CI

4. **Mock/fake drift risk**:
   - Fake client may diverge from real client API
   - No contract tests to verify fake matches reality

---

## Adaptation Recommendations

### Must Replicate

1. **Helper function pattern**:
   ```go
   setupRunFlags()  // Fresh flag set
   parseRun()       // Parse with error handling
   mustParse()      // Parse expecting success
   ```
   These are essential for maintainable tests.

2. **Table-driven test structure**:
   ```go
   tests := []struct {
       name     string
       input    string
       expected ExpectedType
       err      string
   }{...}
   for _, tc := range tests {
       t.Run(tc.name, func(t *testing.T) {...})
   }
   ```

3. **Fake client with function injection**:
   - Per-package `fakeClient` struct
   - Function fields for API methods
   - Safe defaults (return zero values)

4. **Platform-aware testing**:
   - Use `runtime.GOOS` for platform logic
   - `skip.If()` for conditional execution

5. **Assertion library usage**:
   - `gotest.tools/v3/assert` for consistency
   - `is` alias for comparison helpers
   - `t.Helper()` in helper functions

### Suggested Improvements

1. **Add coverage thresholds**:
   - Enforce minimum 80% coverage for new code
   - Fail CI if coverage drops
   - Track coverage trends over time

2. **Create test data factories**:
   ```go
   func makeContainerConfig(opts ...ConfigOption) *container.Config {
       cfg := &container.Config{Image: "busybox", Cmd: []string{"sh"}}
       for _, opt := range opts {
           opt(cfg)
       }
       return cfg
   }
   ```

3. **Add contract tests**:
   - Verify fake client matches real Docker API
   - Run against actual Docker daemon in CI
   - Document differences between fake and real

4. **Centralize test data**:
   - Move hard-coded test data to constants
   - Create shared test fixtures package
   - Use table-driven data even for simple cases

5. **Add benchmark tests**:
   ```go
   func BenchmarkParseRun(b *testing.B) {
       for i := 0; i < b.N; i++ {
           parseRun([]string{"--memory=1G", "ubuntu", "bash"})
       }
   }
   ```

6. **Standardize assertion usage**:
   - Create coding guidelines for `Check` vs `Assert`
   - Document when to use `assert.Equal` vs `is.Equal`
   - Prefer `assert.NilError` over `assert.Check(t, is.Nil(err))`

7. **Add negative test coverage**:
   - Explicitly test that invalid combinations are rejected
   - Test error message quality
   - Validate help text accuracy

### Test Infrastructure Needs

1. **Test helper package**:
   ```
   internal/testutil/
   ├── config.go       # Config factories
   ├── flags.go        # Flag helpers (from opts_test.go)
   ├── client.go       # Shared fake client base
   └── fixtures.go     # Common test data
   ```

2. **Golden file infrastructure**:
   - Document when to use golden files
   - Script to update golden files
   - Clear naming convention

3. **Coverage tooling**:
   - CI job to publish coverage reports
   - Coverage badge in README
   - Diff coverage (only new code)

4. **Platform testing**:
   - Windows CI runner for platform-specific tests
   - macOS CI runner if applicable
   - Document platform test expectations

---

## Summary

The Docker CLI project demonstrates a **mature, well-structured testing strategy** with strong fundamentals:

- **Comprehensive unit tests** using table-driven patterns
- **Effective test isolation** via helper functions
- **Pragmatic integration testing** via fake client pattern
- **Strong platform awareness** with conditional execution
- **Consistent assertion patterns** using `gotest.tools/v3`

The fake client pattern is particularly noteworthy—it provides a **pragmatic balance** between unit testing (fast, isolated) and integration testing (realistic API interaction). The function injection approach is elegant and flexible.

**Key strengths** to replicate:
1. Three-tier helper pattern (setup, parse, mustParse)
2. Table-driven tests with descriptive names
3. Fake client with function injection
4. Platform-specific test handling

**Areas for improvement**:
1. Add coverage enforcement
2. Create test data factories
3. Add contract tests for fake client
4. Centralize test infrastructure

**Testing philosophy**: The project prioritizes **unit test coverage of parsing and validation logic** while relying on **e2e tests for integration scenarios**. This is appropriate for a CLI tool where the core value is in command parsing and flag handling.

For feature adaptation, the **option parsing tests** provide an excellent template for testing shared CLI functionality. The pattern of:
1. Define test cases in table
2. Parse with helper function
3. Assert on configuration objects

...is highly reusable and should be the foundation for testing adapted features.
